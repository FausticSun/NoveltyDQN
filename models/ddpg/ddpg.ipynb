{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klsFNbTF8j62"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "878QD18d7JDC",
    "outputId": "29b87176-9fb3-4407-9edd-5c400450b76b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "cmake is already the newest version (3.10.2-1ubuntu2).\n",
      "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n",
      "libopenmpi-dev is already the newest version (2.1.1-8).\n",
      "swig is already the newest version (3.0.12-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n",
      "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.10.9)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
      "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.6)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.2)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.10.15)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
      "Requirement already satisfied: box2d_py in /usr/local/lib/python3.6/dist-packages (2.3.5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!apt install swig cmake libopenmpi-dev zlib1g-dev\n",
    "!pip install gym\n",
    "!pip install box2d_py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAJVYB0fmsly"
   },
   "source": [
    "# Check if we are allocated a GPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dlFeN7DQDovH",
    "outputId": "670bf4ea-a286-417c-eb7a-897c8c2a678c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lN5wW0Y18oMR"
   },
   "source": [
    "# Connect to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1W29us8L6-Go",
    "outputId": "6a8dc78c-03ea-4a66-a986-ed3e7c40f911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2AooYTa76TDn"
   },
   "source": [
    "# Deep Deterministic Policy Gradient\n",
    "\n",
    "In this implementation, the actions of the BipedalWalker are discretized into 81 actions, each action being a permutation of {-1,0,1} for each of the four outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UTrPpfVa6TDr"
   },
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zIQ2JJ_p6TDv"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import gym\n",
    "import os\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, BatchNormalization, Input, Add, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle # for saving episodes -> rewards\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWVPsYUt6TD8"
   },
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://github.com/openai/baselines/blob/master/baselines/ddpg/noise.py, which is\n",
    "# based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n",
    "class OrnsteinUhlenbeckActionNoise:\n",
    "    def __init__(self, mu, sigma=0.5, theta=.20, dt=1e-2, x0=None):\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "                self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(self.mu, self.sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCOvLXLK6TD-"
   },
   "source": [
    "### Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nx5ibJ9n6TEA"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    This class represents the experience replay buffer\n",
    "    \"\"\"\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer = deque(maxlen=buffer_size)\n",
    "        self.capacity = buffer_size\n",
    "        self.len = 0\n",
    "    \n",
    "    def sample(self, n_samples):\n",
    "        batch = []\n",
    "        n_samples = min(self.len, n_samples)\n",
    "        batch = random.sample(self.buffer, n_samples)\n",
    "        \n",
    "        curr_states = np.float32([arr[0] for arr in batch])\n",
    "        actions = np.int32([arr[1] for arr in batch])\n",
    "        rewards = np.float32([arr[2] for arr in batch])\n",
    "        done = np.bool_([arr[3] for arr in batch])\n",
    "        next_states = np.float32([arr[4] for arr in batch])\n",
    "        \n",
    "        return np.array(curr_states), np.array(actions), np.array(rewards), np.array(done), np.array(next_states)\n",
    "    \n",
    "    def add(self, curr_state, action, reward, done, next_state):\n",
    "        self.buffer.append([curr_state, action, reward, done, next_state])\n",
    "        self.len = self.len + 1\n",
    "        if (self.len > self.capacity):\n",
    "            self.len = self.capacity\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor():\n",
    "    \"\"\"\n",
    "    Input to the network is the state, output is the action\n",
    "    under a deterministic policy.\n",
    "    The output layer activation is a tanh to keep the action\n",
    "    between -action_bound and action_bound\n",
    "    \"\"\"\n",
    "    def __init__(self, state_dim, action_dim, learning_rate, tau):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tau = tau  # tau is the update rate for the target network - allowing it to slowly chase\n",
    "        \n",
    "        # Actor Network\n",
    "        self.model = self.create_actor_network()\n",
    "        self.actor_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(action_dim))\n",
    "        \n",
    "        print(self.model)\n",
    "        # Target Network\n",
    "        self.target = self.create_actor_network()\n",
    "\n",
    "    def create_actor_network(self):\n",
    "        model = Sequential()\n",
    "        #print(model)\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(256, input_dim=self.state_dim, activation='linear'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #print(model)\n",
    "        model.add(Dense(256, activation='linear'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #print(model)\n",
    "        model.add(Dense(256, activation='linear'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        #print(model)\n",
    "        # output of bipedal walker is between -1 and 1\n",
    "        model.add(Dense(self.action_dim, activation='tanh'))\n",
    "        #print(model)\n",
    "        model.compile(\n",
    "            optimizer=Adam(lr=self.learning_rate, ),\n",
    "            loss=\"mse\"\n",
    "        )\n",
    "        #model.summary()\n",
    "        print(model)\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def fit(self, states, action_gradients):\n",
    "        self.model.fit(states, action_gradients)\n",
    "    \n",
    "    def noisy_predict(self, inputs):\n",
    "        return self.model.predict(inputs) + self.actor_noise() \n",
    "    \n",
    "    def predict(self, states):\n",
    "        return self.model.predict(states)\n",
    "\n",
    "    def predict_target(self, states):\n",
    "        return self.target.predict(states)\n",
    "    \n",
    "    def update_target(self):\n",
    "        \"\"\"\n",
    "        Soft update of target network\n",
    "        \"\"\"\n",
    "        self.target.set_weights(\n",
    "            self.model.get_weights() * self.tau + self.target.get_weights() * (1 - self.tau)\n",
    "        )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qauv6GHB6TEJ"
   },
   "source": [
    "## Critic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VadZr9_N6TEL"
   },
   "outputs": [],
   "source": [
    "class Critic():\n",
    "    \"\"\"\n",
    "    This network takes in 2 inputs the state and action, \n",
    "    the output is the Q(s,a)\n",
    "    The input action is given by the Actor\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sess, state_dim, action_dim, \n",
    "                 learning_rate, tau, gamma):\n",
    "        self.sess = sess\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tau = tau\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # Session needed to grab action gradients\n",
    "        K.set_session(sess)\n",
    "\n",
    "        # Create networks\n",
    "        self.model, self.action, self.state = self.create_critic_network()\n",
    "        self.target, self.target_action, self.target_state = self.create_critic_network()\n",
    "        \n",
    "        self.action_grads = tf.gradients(self.model.output, self.action)\n",
    "        self.sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    def create_critic_network(self):\n",
    "        state_inputs = Input(shape=(None,self.state_dim))\n",
    "        action_inputs = Input(shape=(None,self.action_dim))\n",
    "        \n",
    "        state_net = BatchNormalization()(state_inputs)\n",
    "        \n",
    "        state_net = Dense(256)(state_net)\n",
    "        state_net = BatchNormalization()(state_net)\n",
    "        state_net = LeakyReLU(alpha=0.2)(state_net)\n",
    "        \n",
    "        state_net = Dense(256)(state_net)\n",
    "        state_net = BatchNormalization()(state_net)\n",
    "        state_net = LeakyReLU(alpha=0.2)(state_net)\n",
    "        \n",
    "        state_net = Dense(256)(state_net)\n",
    "        state_net = BatchNormalization()(state_net)\n",
    "        state_net = LeakyReLU(alpha=0.2)(state_net)\n",
    "        state_net = Dense(300)(state_net)\n",
    "        \n",
    "        # Actions do not need to be normalized - already between -1 and 1\n",
    "        action_net = Dense(300)(action_inputs)\n",
    "        \n",
    "        # Combine state_net and action_net\n",
    "        net = Add()([state_net, action_net])\n",
    "        net = Dense(300)(net)\n",
    "        net = BatchNormalization()(net)\n",
    "        net = LeakyReLU(alpha=0.2)(net)\n",
    "        net = Dense(1)(net)\n",
    "        \n",
    "        model = keras.models.Model(inputs=[state_inputs, action_inputs], outputs=net)\n",
    "        model.compile(\n",
    "            optimizer=Adam(lr=self.learning_rate),\n",
    "            loss=\"mse\"\n",
    "        )\n",
    "        model.summary()\n",
    "        \n",
    "        return model, state_inputs, action_inputs\n",
    "\n",
    "    def fit(self, states, actions, predicted_q_values):\n",
    "        self.model.fit([states, actions], predicted_q_values)\n",
    "\n",
    "    def predict(self, states, action):\n",
    "        return self.model.predict([states, actions])\n",
    "\n",
    "    def predict_target(self, states, actions):\n",
    "        return self.target.predict([states, actions])\n",
    "    \n",
    "    def get_action_gradients(self, states, actions):\n",
    "        return self.sess.run(\n",
    "            self.action_grads,\n",
    "            feed_dict={\n",
    "                self.state: states,\n",
    "                elf.actions: actions\n",
    "            })[0]\n",
    "    \n",
    "    def update_target(self):\n",
    "        self.target.set_weights(\n",
    "            self.model.get_weights() * self.tau + self.target.get_weights() * (1 - self.tau)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-MSGXm06TES"
   },
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6tv0vTh6TEU"
   },
   "outputs": [],
   "source": [
    "class DDPGAgent:\n",
    "    def __init__(self, sess, state_dim, action_dim, buffer_size=30000, \n",
    "                 learning_rate=0.001, batch_size=64, gamma=0.9, \n",
    "                 epsilon=1.00, epsilon_decay=0.99999, epsilon_min=0.001,\n",
    "                 name='DDPG', tau=0.001):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.tau = tau\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        \n",
    "        self.name = name;\n",
    "        \n",
    "        self.actor = Actor(state_dim, action_dim, learning_rate, tau)\n",
    "        self.critic = Critic(sess, state_dim, action_dim, learning_rate, tau, gamma)\n",
    "        \n",
    "        self.buffer = ReplayBuffer(buffer_size)\n",
    "        \n",
    "    \n",
    "    def get_noisy_action(self, states):\n",
    "        states = np.reshape(states, (1, self.state_dim))\n",
    "        return self.actor.noisy_predict(states)\n",
    "    \n",
    "    \n",
    "    def train_model(self):     \n",
    "        if (self.buffer.len > self.batch_size):\n",
    "            states, actions, rewards, done, next_states = self.buffer.sample(self.batch_size)\n",
    "            target_q = self.critic.predict_target(next_states, actions)\n",
    "            \n",
    "            targets = []\n",
    "            for i in range(self.batch_size):\n",
    "                if (done[i]):\n",
    "                    targets.append(rewards[i])\n",
    "                else:\n",
    "                    targets.append(rewards[i] + self.gamma + target_q[i])\n",
    "            \n",
    "            # Update critic\n",
    "            self.critic.fit(states, actions, np.reshape(targets, (-1,1)))\n",
    "            \n",
    "            actor_actions = self.actor.predict(states)\n",
    "            action_gradients = critic.get_action_gradients(states, actor_actions)\n",
    "            actor.fit(states, action_gradients)\n",
    "            \n",
    "            actor.update_target()\n",
    "            critic.update_target()\n",
    "    \n",
    "    def store_transition(self, state, action, reward, done, next_state):\n",
    "        self.buffer.add(state, action, reward, done, next_state)\n",
    "    \n",
    "    def save_model(self, n_episodes):\n",
    "        GOOGLE_DIR = '/content/gdrive/My Drive/cs4246_project/models/ddpg/trained_models/'\n",
    "        HOME_DIR = './trained_models/'\n",
    "        self.model.model.save(GOOGLE_DIR + self.name + '_ep' + str(n_episodes) + '.h5')\n",
    "        pass\n",
    "    \n",
    "    def load_model(self, model_name):\n",
    "        self.model = keras.models.load_model(model_name)\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHEuO73V6TEd"
   },
   "source": [
    "## Setup Gym Environment and Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "JVp6RZN76TEg",
    "outputId": "1b159883-80d2-4bed-8c81-131bad36cbcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "<keras.engine.sequential.Sequential object at 0x7f5cd841e710>\n",
      "<keras.engine.sequential.Sequential object at 0x7f5cd841e710>\n",
      "<keras.engine.sequential.Sequential object at 0x7f5cd830ab70>\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_56 (InputLayer)           (None, None, 24)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, None, 24)     96          input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_353 (Dense)               (None, None, 256)    6400        batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, None, 256)    1024        dense_353[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_233 (LeakyReLU)     (None, None, 256)    0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_354 (Dense)               (None, None, 256)    65792       leaky_re_lu_233[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, None, 256)    1024        dense_354[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_234 (LeakyReLU)     (None, None, 256)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_355 (Dense)               (None, None, 256)    65792       leaky_re_lu_234[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, None, 256)    1024        dense_355[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_235 (LeakyReLU)     (None, None, 256)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "input_57 (InputLayer)           (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_356 (Dense)               (None, None, 300)    77100       leaky_re_lu_235[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_357 (Dense)               (None, None, 300)    1500        input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, 300)    0           dense_356[0][0]                  \n",
      "                                                                 dense_357[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_358 (Dense)               (None, None, 300)    90300       add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, None, 300)    1200        dense_358[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_236 (LeakyReLU)     (None, None, 300)    0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_359 (Dense)               (None, None, 1)      301         leaky_re_lu_236[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 311,553\n",
      "Trainable params: 309,369\n",
      "Non-trainable params: 2,184\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_58 (InputLayer)           (None, None, 24)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, None, 24)     96          input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_360 (Dense)               (None, None, 256)    6400        batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, None, 256)    1024        dense_360[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_237 (LeakyReLU)     (None, None, 256)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_361 (Dense)               (None, None, 256)    65792       leaky_re_lu_237[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, None, 256)    1024        dense_361[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_238 (LeakyReLU)     (None, None, 256)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_362 (Dense)               (None, None, 256)    65792       leaky_re_lu_238[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, None, 256)    1024        dense_362[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_239 (LeakyReLU)     (None, None, 256)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "input_59 (InputLayer)           (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_363 (Dense)               (None, None, 300)    77100       leaky_re_lu_239[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_364 (Dense)               (None, None, 300)    1500        input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, None, 300)    0           dense_363[0][0]                  \n",
      "                                                                 dense_364[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_365 (Dense)               (None, None, 300)    90300       add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, None, 300)    1200        dense_365[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_240 (LeakyReLU)     (None, None, 300)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_366 (Dense)               (None, None, 1)      301         leaky_re_lu_240[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 311,553\n",
      "Trainable params: 309,369\n",
      "Non-trainable params: 2,184\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BipedalWalker-v2')\n",
    "n_state_params = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.shape[0]\n",
    "\n",
    "# allow GPU optimization\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#sess = tf.Session(config=config)\n",
    "sess = tf.Session()\n",
    "\n",
    "agent = DDPGAgent(sess, n_state_params, n_actions)\n",
    "BATCH_SIZE = 64\n",
    "MAX_EPISODES = 100000\n",
    "MAX_REWARD = 300\n",
    "MAX_STEPS = env._max_episode_steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRZVGKeT6TEu"
   },
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388319
    },
    "colab_type": "code",
    "id": "dU6wltrp6TEv",
    "outputId": "bf2746ff-a283-4c4b-cadf-8510dbae5848"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_58 to have 3 dimensions, but got array with shape (64, 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-37d643e45388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misDone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misDone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-6081669f8377>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mtarget_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-120-aa3c24c8a5f3>\u001b[0m in \u001b[0;36mpredict_target\u001b[0;34m(self, states, actions)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_action_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4246_project/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4246_project/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs4246_project/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_58 to have 3 dimensions, but got array with shape (64, 24)"
     ]
    }
   ],
   "source": [
    "for ep in range(MAX_EPISODES):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    for t in range(MAX_STEPS):\n",
    "        state = np.reshape(state, [1, n_state_params])\n",
    "        actions = agent.get_noisy_action(state)\n",
    "        state = np.reshape(state, [n_state_params])\n",
    "        next_state, reward, isDone, _ = env.step(actions[0])\n",
    "        \n",
    "        agent.store_transition(state, actions[0], reward, isDone, next_state)\n",
    "        state = next_state\n",
    "        agent.train_model()\n",
    "        total_reward += reward\n",
    "        if (isDone):\n",
    "            print(\"episode: {}/{}, score: {}, e: {:.2}\".format(ep, MAX_EPISODES, total_reward, agent.epsilon))\n",
    "            break\n",
    "        \n",
    "        if (agent.buffer.len > BATCH_SIZE):\n",
    "            agent.train_model()\n",
    "    \n",
    "    # record rewards dynamically\n",
    "    GOOGLE_FILE = '/content/gdrive/My Drive/cs4246_project/models/ddpg/record.dat'\n",
    "    HOME_FILE = './record.dat'\n",
    "    record_filename = GOOGLE_FILE\n",
    "    data = [ep, total_reward]\n",
    "    with open(record_filename, \"ab\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    \n",
    "    if (total_reward > 200):\n",
    "        agent.save_model(ep)\n",
    "        break\n",
    "    \n",
    "    # save model every 10000 episodes\n",
    "    if ((ep % 10000) == 0):\n",
    "        agent.save_model(ep)\n",
    "    \n",
    "    if (total_reward > 200):\n",
    "        agent.save_model(ep)\n",
    "        break\n",
    "    \n",
    "    # save model every 100 episodes\n",
    "    if ((ep % 100) == 0):\n",
    "        agent.save_model(ep)\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "gb57315V6TE-",
    "outputId": "a8dd2a4d-a08a-4f7e-f074-b7bd6763aa33"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-ea88bf1c9ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "with open(record_filename, 'rb') as fr:\n",
    "    try:\n",
    "        while True:\n",
    "            data.append(pickle.load(fr))\n",
    "    except EOFError:\n",
    "        pass\n",
    "data = pd.DataFrame(np.array(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVShNuG46TFG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "discrete_dqn.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python (cs4246_project)",
   "language": "python",
   "name": "cs4246_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
